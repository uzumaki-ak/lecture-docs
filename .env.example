# ========================================
# FILE 2: .env.example
# Purpose: Template for environment variables
# Copy this to .env and fill in your values
# ========================================

# ============================================
# DATABASE CONFIGURATION
# ============================================
POSTGRES_DB=lecture_docs
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_PORT=5432
DATABASE_URL=postgresql://postgres:your_secure_password_here@localhost:5432/lecture_docs

# ============================================
# REDIS CONFIGURATION
# ============================================
REDIS_URL=redis://localhost:6379/0
REDIS_PORT=6379

# ============================================
# VECTOR DATABASE (CHROMA)
# ============================================
CHROMA_HOST=localhost
CHROMA_PORT=8000
VECTOR_DB=chroma  # Options: chroma, qdrant

# ============================================
# APPLICATION MODE
# ============================================
MODE=local  # Options: local, cloud
PRIVACY_MODE=no-cloud  # Set to prevent any cloud API calls
DEV_AUTH=true  # Set to false when using Clerk
NODE_ENV=development
LOG_LEVEL=info  # Options: debug, info, warning, error

# ============================================
# LLM PROVIDERS (Multiple fallbacks)
# ============================================
# Primary LLM provider (first to try)
LLM_PROVIDER=gemini  # Options: gemini, euron, openai, anthropic, local

# GEMINI (FREE) - Get key at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp  # Free tier model

# EURON.ONE (FREE) - Get key at: https://www.euron.one/api-keys
EURON_API_KEY=your_euron_api_key_here
EURON_BASE_URL=https://api.euron.one/api/v1/euri
EURON_CHAT_MODEL=gpt-4.1-nano
EURON_EMBEDDING_MODEL=text-embedding-3-small

# OPENAI (OPTIONAL/PAID) - Get key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini  # Cheapest option

# ANTHROPIC (OPTIONAL/PAID) - Get key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-haiku-20241022  # Fastest/cheapest

# LOCAL MODELS (FREE)
LOCAL_LLM_PATH=/app/models/llama-3.2-3b-instruct.gguf
LOCAL_LLM_URL=http://localhost:11434  # Ollama endpoint
USE_LOCAL_LLM=true

# ============================================
# EMBEDDING PROVIDERS (Multiple fallbacks)
# ============================================
EMBEDDINGS_PROVIDER=sentence-transformers  # Options: sentence-transformers, gemini, euron, openai
EMBEDDING_MODEL=all-MiniLM-L6-v2  # Local sentence-transformers model
EMBEDDING_DIMENSION=384  # Dimension for all-MiniLM-L6-v2

# ============================================
# OCR CONFIGURATION
# ============================================
OCR_PROVIDER=tesseract  # Options: tesseract, trocr, paddle
TROCR_MODEL=microsoft/trocr-base-handwritten
USE_GPU=false  # Set to true if GPU available
TESSERACT_LANG=eng  # Languages: eng, hin, etc.

# ============================================
# SPEECH-TO-TEXT (STT)
# ============================================
STT_PROVIDER=whisper  # Options: whisper, gemini, euron
WHISPER_MODEL=base  # Options: tiny, base, small, medium, large
WHISPER_DEVICE=cpu  # Options: cpu, cuda

# ============================================
# FILE UPLOAD LIMITS
# ============================================
MAX_UPLOAD_SIZE_MB=50
MAX_FILE_COUNT=20
ALLOWED_EXTENSIONS=jpg,jpeg,png,pdf,mp3,mp4,wav,m4a,zip,py,js,ts,sol,md,txt

# ============================================
# RATE LIMITING
# ============================================
RATE_LIMIT_UPLOADS_PER_HOUR=10
RATE_LIMIT_CHAT_PER_MINUTE=20
RATE_LIMIT_ENABLED=true

# ============================================
# JOB QUEUE CONFIGURATION
# ============================================
WORKER_CONCURRENCY=2  # Number of parallel processing jobs
JOB_TIMEOUT_SECONDS=600  # 10 minutes
RETRY_ATTEMPTS=3

# ============================================
# AUTHENTICATION
# ============================================
# CLERK (OPTIONAL) - Get keys at: https://clerk.com/
CLERK_SECRET_KEY=your_clerk_secret_key_here
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=your_clerk_publishable_key_here
CLERK_WEBHOOK_SECRET=your_clerk_webhook_secret_here

# JWT for dev auth (when DEV_AUTH=true)
JWT_SECRET=your_super_secret_jwt_key_change_this_in_production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=10080  # 7 days

# ============================================
# FRONTEND CONFIGURATION
# ============================================
NEXT_PUBLIC_API_URL=http://localhost:8080
NEXT_PUBLIC_APP_NAME=LectureDocs
FRONTEND_PORT=3000
BACKEND_PORT=8080

# ============================================
# CHUNKING CONFIGURATION
# ============================================
CHUNK_SIZE=1000  # tokens
CHUNK_OVERLAP=200  # tokens
MIN_CHUNK_SIZE=100
PRESERVE_CODE_BLOCKS=true

# ============================================
# RAG CONFIGURATION
# ============================================
RAG_TOP_K=10  # Number of chunks to retrieve
RAG_SIMILARITY_THRESHOLD=0.7
CONTEXT_WINDOW=8000  # tokens
MAX_CHAT_HISTORY=10  # messages

# ============================================
# STORAGE CONFIGURATION
# ============================================
UPLOAD_DIR=/app/uploads
MODELS_DIR=/app/models
TEMP_DIR=/tmp/lecture-docs

# ============================================
# MONITORING & OBSERVABILITY (OPTIONAL)
# ============================================
SENTRY_DSN=your_sentry_dsn_here
ENABLE_TELEMETRY=false
PROMETHEUS_PORT=9090

# ============================================
# SCALING CONFIGURATION
# ============================================
WORKERS=4  # Uvicorn workers
KEEP_ALIVE=65
MAX_CONNECTIONS=1000
BACKLOG=2048

# ============================================
# CACHE CONFIGURATION
# ============================================
REDIS_MAX_MEMORY=512mb
CACHE_TTL_SECONDS=3600  # 1 hour
ENABLE_RESULT_CACHE=true

# ============================================
# YOUTUBE TRANSCRIPT
# ============================================
YOUTUBE_API_KEY=your_youtube_api_key_here  # Optional, uses yt-dlp by default

# ============================================
# ADDITIONAL API KEYS FOR FALLBACKS
# ============================================
# Add multiple keys for each provider to handle rate limits
GEMINI_API_KEY_2=
GEMINI_API_KEY_3=
EURON_API_KEY_2=
EURON_API_KEY_3=
OPENAI_API_KEY_2=

# ============================================
# FEATURE FLAGS
# ============================================
ENABLE_YOUTUBE_UPLOAD=true
ENABLE_AUDIO_UPLOAD=true
ENABLE_VIDEO_UPLOAD=true
ENABLE_ZIP_UPLOAD=true
ENABLE_GITHUB_SYNC=true
ENABLE_EXPORT_PDF=false

# ============================================
# DOCUMENTATION GENERATION
# ============================================
GENERATE_EXAMPLES=true
GENERATE_MERMAID=true
CHILD_FRIENDLY_MODE=true
INCLUDE_TODOS=true

# ============================================
# WHERE TO GET API KEYS
# ============================================
# 1. Gemini (FREE): https://aistudio.google.com/app/apikey
# 2. Euron.one (FREE): https://www.euron.one/api-keys
# 3. OpenAI (PAID): https://platform.openai.com/api-keys
# 4. Anthropic (PAID): https://console.anthropic.com/
# 5. Clerk (FREE tier): https://clerk.com/
# 6. Supabase (FREE tier): https://supabase.com/
# 7. YouTube API (FREE quota): https://console.cloud.google.com/